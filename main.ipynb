{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8949bc18",
   "metadata": {},
   "source": [
    "## Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9bbd9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, io\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "from IPython.display import clear_output\n",
    "\n",
    "ridership_df = pd.DataFrame()\n",
    "\n",
    "links = [\n",
    "    'https://www.bart.gov/sites/default/files/2025-11/Ridership_202510.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-10/Ridership_202509.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-10/Ridership_202508.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-08/Ridership_202507.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-07/Ridership_202506.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-06/Ridership_202505.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-05/Ridership_202504.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-05/Ridership_202503.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-03/Ridership_202502.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-02/Ridership_202501.xlsx'\n",
    "]\n",
    "\n",
    "def extract_date_from_link(link):\n",
    "    \"\"\"\n",
    "    Extract substring between 'Ridership_' and '.xlsx'.\n",
    "    Example: 'Ridership_202510.xlsx' → '202510'\n",
    "    \"\"\"\n",
    "    start = link.find(\"Ridership_\") + len(\"Ridership_\")\n",
    "    end = link.find(\".xlsx\")\n",
    "    return link[start:end]\n",
    "\n",
    "def set_header_row(df, keyword=\"Exit Station Two-Letter Code\"):\n",
    "    \"\"\"\n",
    "    Find the row containing keyword and use it as the column headers.\n",
    "    Return the cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # locate the header row index\n",
    "    header_idx = df.index[df.apply(lambda row: row.astype(str).str.contains(keyword).any(), axis=1)]\n",
    "    \n",
    "    if len(header_idx) == 0:\n",
    "        # no header row found — return unchanged\n",
    "        return df\n",
    "    \n",
    "    header_idx = header_idx[0]\n",
    "\n",
    "    # set the header\n",
    "    new_header = df.iloc[header_idx]\n",
    "    df = df[header_idx + 1 :]  # drop the header row and all above it\n",
    "    df.columns = new_header\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "for link in links:\n",
    "    response = requests.get(link)\n",
    "\n",
    "    df = pd.read_excel(\n",
    "        io.BytesIO(response.content),\n",
    "        engine='openpyxl',\n",
    "        header=None,                    \n",
    "        sheet_name='Average Weekday'\n",
    "    )\n",
    "\n",
    "    df = set_header_row(df)\n",
    "\n",
    "    # Add extracted date\n",
    "    df[\"date\"] = extract_date_from_link(link)            \n",
    "\n",
    "    ridership_df = pd.concat([ridership_df, df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f2334d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.bart.gov/sites/default/files/docs/station-names.xls\n",
    "\n",
    "station_map_df = pd.DataFrame({\n",
    "    \"code\": [\n",
    "        \"RM\",\"EN\",\"EP\",\"NB\",\"BK\",\"AS\",\"MA\",\"19\",\"12\",\"LM\",\"FV\",\"CL\",\"SL\",\"BF\",\"HY\",\"SH\",\n",
    "        \"UC\",\"FM\",\"CN\",\"PH\",\"WC\",\"LF\",\"OR\",\"RR\",\"OW\",\"EM\",\"MT\",\"PL\",\"CC\",\"16\",\"24\",\"GP\",\n",
    "        \"BP\",\"DC\",\"CM\",\"CV\",\"ED\",\"NC\",\"WP\",\"SS\",\"SB\",\"SO\",\"MB\",\"WD\",\"OA\",\"WS\",\"AN\",\"PC\",\n",
    "        \"ML\",\"BE\"\n",
    "    ],\n",
    "    \"stop_name\": [\n",
    "        \"Richmond\",\"El Cerrito Del Norte\",\"El Cerrito Plaza\",\"North Berkeley\",\n",
    "        \"Downtown Berkeley\",\"Ashby\",\"MacArthur\",\"19th Street Oakland\",\n",
    "        \"12th Street / Oakland City Center\",\"Lake Merritt\",\"Fruitvale\",\"Coliseum - OAC\",\n",
    "        \"San Leandro\",\"Bay Fair\",\"Hayward\",\"South Hayward\",\"Union City\",\"Fremont\",\n",
    "        \"Concord\",\"Pleasant Hill / Contra Costa Centre\",\"Walnut Creek\",\"Lafayette\",\"Orinda\",\"Rockridge\",\n",
    "        \"West Oakland\",\"Embarcadero\",\"Montgomery Street\",\"Powell Street\",\n",
    "        \"Civic Center / UN Plaza\",\"16th Street / Mission\",\"24th Street / Mission\",\"Glen Park\",\n",
    "        \"Balboa Park\",\"Daly City\",\"Colma\",\"Castro Valley\",\"Dublin / Pleasanton\",\n",
    "        \"North Concord / Martinez\",\"Pittsburg / Bay Point\",\"South San Francisco\",\"San Bruno\",\n",
    "        \"San Francisco International Airport\",\"Millbrae (Caltrain Transfer Platform)\",\"West Dublin / Pleasanton\",\n",
    "        \"Oakland International Airport Station\",\"Warm Springs / South Fremont\",\"Antioch\",\"Pittsburg Center\",\n",
    "        \"Milpitas\",\"Berryessa / North San Jose\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f645f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS_URL = \"https://www.bart.gov/dev/schedules/google_transit.zip\"\n",
    "\n",
    "response = requests.get(GTFS_URL)\n",
    "z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "# Load GTFS components into DataFrames\n",
    "routes = pd.read_csv(z.open(\"routes.txt\"))\n",
    "stops = pd.read_csv(z.open(\"stops.txt\"))\n",
    "trips = pd.read_csv(z.open(\"trips.txt\"), dtype={\"route_id\": str})\n",
    "stop_times = pd.read_csv(z.open(\"stop_times.txt\"))\n",
    "calendar = pd.read_csv(z.open(\"calendar.txt\"))\n",
    "\n",
    "# Join trips with routes\n",
    "trip_routes = trips.merge(routes, on=\"route_id\", how=\"left\")\n",
    "\n",
    "# Join stop_times with stops\n",
    "times_with_stops = stop_times.merge(stops, on=\"stop_id\", how=\"left\")\n",
    "\n",
    "# Final joined table\n",
    "full_schedule = (\n",
    "    trip_routes\n",
    "    .merge(times_with_stops, on=\"trip_id\", how=\"left\")\n",
    "    .sort_values([\"route_id\", \"trip_id\", \"stop_sequence\"])\n",
    ")\n",
    "\n",
    "full_schedule['stop_name'] = full_schedule['stop_name'].str.replace(\"\", \"\", regex=False)\n",
    "\n",
    "mapped_schedule = full_schedule.merge(station_map_df, left_on=\"stop_name\", right_on=\"stop_name\", how=\"left\")\n",
    "\n",
    "# mapped_schedule.to_excel(\"C:/Users/chhri/Downloads/bart_full_schedule.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fe227e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "\n",
    "stops_df = mapped_schedule.copy()\n",
    "\n",
    "def parse_gtfs_time(t):\n",
    "    \"\"\"\n",
    "    Parse time strings like '06:11:00' or '24:05:00' into minutes since midnight.\n",
    "    GTFS allows hours >= 24, meaning times past midnight but same service day.\n",
    "    \"\"\"\n",
    "    if pd.isna(t):\n",
    "        return np.nan\n",
    "    hh, mm, ss = map(int, str(t).split(\":\"))\n",
    "    return hh * 60 + mm + ss / 60.0   # minutes since midnight (possibly > 24*60)\n",
    "\n",
    "def compute_travel_times(stops_df):\n",
    "    df = stops_df.copy()\n",
    "\n",
    "    # parse times into numeric minutes\n",
    "    df[\"arr_min\"] = df[\"arrival_time\"].apply(parse_gtfs_time)\n",
    "    df[\"dep_min\"] = df[\"departure_time\"].apply(parse_gtfs_time)\n",
    "\n",
    "    # sort properly\n",
    "    df = df.sort_values([\"route_id\", \"trip_id\", \"stop_sequence\"])\n",
    "\n",
    "    arc_rows = []\n",
    "\n",
    "    for (route_id, trip_id), group in df.groupby([\"route_id\", \"trip_id\"]):\n",
    "        group = group.sort_values(\"stop_sequence\")\n",
    "\n",
    "        dep_times = group[\"dep_min\"].values\n",
    "        arr_times = group[\"arr_min\"].values\n",
    "        seq      = group[\"stop_sequence\"].values\n",
    "        codes    = group[\"code\"].values\n",
    "        dep_str  = group[\"departure_time\"].values\n",
    "        arr_str  = group[\"arrival_time\"].values\n",
    "\n",
    "        for i in range(len(group) - 1):\n",
    "            travel = arr_times[i+1] - dep_times[i]   # minutes\n",
    "            travel_min = int(round(travel))\n",
    "\n",
    "            arc_rows.append({\n",
    "                \"route_id\": route_id,\n",
    "                \"trip_id\": trip_id,\n",
    "                \"from_stop\": codes[i],\n",
    "                \"to_stop\": codes[i+1],\n",
    "                \"from_seq\": seq[i],\n",
    "                \"to_seq\": seq[i+1],\n",
    "                \"dep_time_str\": dep_str[i],\n",
    "                \"arr_time_str\": arr_str[i+1],\n",
    "                \"travel_time_min\": travel_min\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(arc_rows)\n",
    "\n",
    "arc_df = compute_travel_times(stops_df)\n",
    "\n",
    "def build_nodes(arc_df):\n",
    "    # each \"to\" event defines a station–time node\n",
    "    nodes = arc_df[\"to_stop\"] + \"_\" + arc_df[\"arr_time_str\"]\n",
    "    V = list(nodes.unique())\n",
    "    return V\n",
    "\n",
    "V = build_nodes(arc_df)\n",
    "\n",
    "def build_stage_arcs(arc_df):\n",
    "    A_stage = []\n",
    "    for row in arc_df.itertuples(index=False):\n",
    "        arc_name = f\"{row.from_stop}_{row.dep_time_str}__{row.to_stop}_{row.arr_time_str}\"\n",
    "        A_stage.append({\n",
    "            \"arc\": arc_name,\n",
    "            \"from_node\": f\"{row.from_stop}_{row.dep_time_str}\",\n",
    "            \"to_node\":   f\"{row.to_stop}_{row.arr_time_str}\",\n",
    "            \"travel_time\": row.travel_time_min,\n",
    "            \"origin_code\": row.from_stop,\n",
    "            \"dest_code\":   row.to_stop,\n",
    "            \"trip_id\":     row.trip_id\n",
    "        })\n",
    "    return A_stage\n",
    "\n",
    "A_stage = build_stage_arcs(arc_df)\n",
    "\n",
    "# index ridership by origin\n",
    "ridership_df_idx = ridership_df.set_index(\"Exit Station Two-Letter Code\")\n",
    "\n",
    "def build_projected_ridership_dict(ridership_df_idx, growth_rate=1.0):\n",
    "    \"\"\"\n",
    "    Returns a dict: projected_lookup[(origin, dest)] = scalar ridership.\n",
    "    Applies an optional growth factor.\n",
    "    \"\"\"\n",
    "    clean_index = ridership_df_idx.index\n",
    "    clean_index = clean_index[~clean_index.isin([\"Grand Total\"])]\n",
    "    clean_index = clean_index.dropna()\n",
    "\n",
    "    clean_cols = ridership_df_idx.columns\n",
    "    clean_cols = clean_cols[~clean_cols.isin([\"Grand Total\", \"date\"])]\n",
    "    clean_cols = clean_cols.dropna()\n",
    "\n",
    "    projected_lookup = {}\n",
    "\n",
    "    for origin in clean_index:\n",
    "        for dest in clean_cols:\n",
    "            vals = ridership_df_idx.loc[origin, dest]\n",
    "\n",
    "            if isinstance(vals, pd.Series):\n",
    "                vals = vals.dropna()\n",
    "                avg_ridership = vals.mean()\n",
    "            else:\n",
    "                avg_ridership = float(vals) if pd.notna(vals) else 0.0\n",
    "\n",
    "            projected = avg_ridership * growth_rate\n",
    "            projected_lookup[(origin, dest)] = float(projected)\n",
    "\n",
    "    return projected_lookup\n",
    "\n",
    "projected_lookup = build_projected_ridership_dict(ridership_df_idx, growth_rate=1.0)\n",
    "\n",
    "def compute_demand_for_arcs(A_stage, projected_lookup, stops_df):\n",
    "    \"\"\"\n",
    "    Compute scalar demand d_a for each arc using projected OD demand.\n",
    "    d_a = sum of riders who board at origin and exit at any downstream stop\n",
    "          along that trip.\n",
    "    \"\"\"\n",
    "    # Precompute stop order for each trip\n",
    "    stop_orders = {}\n",
    "    for trip_id, group in stops_df.groupby(\"trip_id\"):\n",
    "        group_sorted = group.sort_values(\"stop_sequence\")\n",
    "        stop_orders[trip_id] = list(group_sorted[\"code\"])\n",
    "\n",
    "    demand_dict = {}\n",
    "\n",
    "    for arc in A_stage:\n",
    "        trip_id = arc[\"trip_id\"]\n",
    "        origin = arc[\"origin_code\"]\n",
    "        dest   = arc[\"dest_code\"]\n",
    "\n",
    "        stops = stop_orders[trip_id]\n",
    "        idx_origin = stops.index(origin)\n",
    "        idx_dest   = stops.index(dest)\n",
    "\n",
    "        downstream = stops[idx_dest:]   # dest and all following stops\n",
    "\n",
    "        d_sum = 0.0\n",
    "        for down_station in downstream:\n",
    "            if not isinstance(down_station, str):\n",
    "                continue\n",
    "            key = (origin, down_station)\n",
    "            d_sum += projected_lookup.get(key, 0.0)\n",
    "\n",
    "        demand_dict[arc[\"arc\"]] = float(d_sum)\n",
    "\n",
    "    return demand_dict\n",
    "\n",
    "d = compute_demand_for_arcs(A_stage, projected_lookup, stops_df)\n",
    "\n",
    "# Remove duplicates based on the 'arc' field\n",
    "seen = set()\n",
    "A_stage_unique = []\n",
    "\n",
    "for a in A_stage:\n",
    "    if a[\"arc\"] not in seen:\n",
    "        A_stage_unique.append(a)\n",
    "        seen.add(a[\"arc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aaaac775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: 13th Gen Intel(R) Core(TM) i7-13700K, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 24 logical processors, using up to 24 threads\n",
      "\n",
      "Optimize a model with 29038 rows, 14519 columns and 29038 nonzeros\n",
      "Model fingerprint: 0xc8b0a832\n",
      "Variable types: 0 continuous, 14519 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+02]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [5e+00, 7e+03]\n",
      "Presolve removed 343 rows and 0 columns\n",
      "Presolve time: 0.00s\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.01 work units)\n",
      "Thread count was 1 (of 24 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Model is infeasible\n",
      "Best objective -, best bound -, gap -\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Unable to retrieve attribute 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 38\u001b[0m\n\u001b[0;32m     31\u001b[0m     model\u001b[38;5;241m.\u001b[39maddConstr(\n\u001b[0;32m     32\u001b[0m         m_seats_per_unit \u001b[38;5;241m*\u001b[39m t[name] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m d[name],\n\u001b[0;32m     33\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemand_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     )\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[1;32m---> 38\u001b[0m solution \u001b[38;5;241m=\u001b[39m {arc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marc\u001b[39m\u001b[38;5;124m\"\u001b[39m]: t[arc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marc\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mX \u001b[38;5;28;01mfor\u001b[39;00m arc \u001b[38;5;129;01min\u001b[39;00m A_stage_unique}\n",
      "Cell \u001b[1;32mIn[119], line 38\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m     model\u001b[38;5;241m.\u001b[39maddConstr(\n\u001b[0;32m     32\u001b[0m         m_seats_per_unit \u001b[38;5;241m*\u001b[39m t[name] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m d[name],\n\u001b[0;32m     33\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemand_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m     )\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[1;32m---> 38\u001b[0m solution \u001b[38;5;241m=\u001b[39m {arc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marc\u001b[39m\u001b[38;5;124m\"\u001b[39m]: t[arc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marc\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mX \u001b[38;5;28;01mfor\u001b[39;00m arc \u001b[38;5;129;01min\u001b[39;00m A_stage_unique}\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\var.pxi:128\u001b[0m, in \u001b[0;36mgurobipy._core.Var.__getattr__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\var.pxi:156\u001b[0m, in \u001b[0;36mgurobipy._core.Var.getAttr\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\_attrutil.pyx:117\u001b[0m, in \u001b[0;36mgurobipy._attrutil._getattr\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Unable to retrieve attribute 'X'"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Model(\"Bart_Fleet_Optimization\")\n",
    "\n",
    "# t[a] = integer number of train units assigned to arc a\n",
    "t = model.addVars(\n",
    "    [arc[\"arc\"] for arc in A_stage_unique],\n",
    "    vtype=GRB.INTEGER,\n",
    "    lb=0,\n",
    "    name=\"t\"\n",
    ")\n",
    "\n",
    "model.setObjective(\n",
    "    quicksum(arc[\"travel_time\"] * t[arc[\"arc\"]] for arc in A_stage_unique),\n",
    "    GRB.MINIMIZE\n",
    ")\n",
    "\n",
    "# fleet-style objective (unweighted)\n",
    "model.setObjective(\n",
    "    quicksum(t[arc[\"arc\"]] for arc in A_stage_unique),\n",
    "    GRB.MINIMIZE\n",
    ")\n",
    "\n",
    "m_seats_per_unit = 163  # seats per car / unit\n",
    "n_max_units      = 5    # max units per train\n",
    "\n",
    "for arc in A_stage_unique:\n",
    "    name = arc[\"arc\"]\n",
    "    model.addConstr(t[name] <= n_max_units, name=f\"cap_{name}\")\n",
    "\n",
    "for arc in A_stage_unique:\n",
    "    name = arc[\"arc\"]\n",
    "    model.addConstr(\n",
    "        m_seats_per_unit * t[name] >= d[name],\n",
    "        name=f\"demand_{name}\"\n",
    "    )\n",
    "\n",
    "model.optimize()\n",
    "\n",
    "solution = {arc[\"arc\"]: t[arc[\"arc\"]].X for arc in A_stage_unique}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "67d33444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52646 14519\n"
     ]
    }
   ],
   "source": [
    "arcs = [a[\"arc\"] for a in A_stage]\n",
    "unique_arcs = set(arcs)\n",
    "\n",
    "print(len(arcs), len(unique_arcs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
