{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8949bc18",
   "metadata": {},
   "source": [
    "## Gather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "52684bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, io\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9bbd9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ridership_df = pd.DataFrame()\n",
    "\n",
    "links = [\n",
    "    'https://www.bart.gov/sites/default/files/2025-11/Ridership_202510.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-10/Ridership_202509.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-10/Ridership_202508.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-08/Ridership_202507.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-07/Ridership_202506.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-06/Ridership_202505.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-05/Ridership_202504.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-05/Ridership_202503.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-03/Ridership_202502.xlsx',\n",
    "    'https://www.bart.gov/sites/default/files/2025-02/Ridership_202501.xlsx'\n",
    "]\n",
    "\n",
    "def extract_date_from_link(link):\n",
    "    \"\"\"\n",
    "    Extract substring between 'Ridership_' and '.xlsx'.\n",
    "    Example: 'Ridership_202510.xlsx' → '202510'\n",
    "    \"\"\"\n",
    "    start = link.find(\"Ridership_\") + len(\"Ridership_\")\n",
    "    end = link.find(\".xlsx\")\n",
    "    return link[start:end]\n",
    "\n",
    "def set_header_row(df, keyword=\"Exit Station Two-Letter Code\"):\n",
    "    \"\"\"\n",
    "    Find the row containing keyword and use it as the column headers.\n",
    "    Return the cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # locate the header row index\n",
    "    header_idx = df.index[df.apply(lambda row: row.astype(str).str.contains(keyword).any(), axis=1)]\n",
    "    \n",
    "    if len(header_idx) == 0:\n",
    "        # no header row found — return unchanged\n",
    "        return df\n",
    "    \n",
    "    header_idx = header_idx[0]\n",
    "\n",
    "    # set the header\n",
    "    new_header = df.iloc[header_idx]\n",
    "    df = df[header_idx + 1 :]  # drop the header row and all above it\n",
    "    df.columns = new_header\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "for link in links:\n",
    "    response = requests.get(link)\n",
    "\n",
    "    df = pd.read_excel(\n",
    "        io.BytesIO(response.content),\n",
    "        engine='openpyxl',\n",
    "        header=None,                    \n",
    "        sheet_name='Average Weekday'\n",
    "    )\n",
    "\n",
    "    df = set_header_row(df)\n",
    "\n",
    "    # Add extracted date\n",
    "    df[\"date\"] = extract_date_from_link(link)            \n",
    "\n",
    "    ridership_df = pd.concat([ridership_df, df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f2334d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.bart.gov/sites/default/files/docs/station-names.xls\n",
    "\n",
    "station_map_df = pd.DataFrame({\n",
    "    \"code\": [\n",
    "        \"RM\",\"EN\",\"EP\",\"NB\",\"BK\",\"AS\",\"MA\",\"19\",\"12\",\"LM\",\"FV\",\"CL\",\"SL\",\"BF\",\"HY\",\"SH\",\n",
    "        \"UC\",\"FM\",\"CN\",\"PH\",\"WC\",\"LF\",\"OR\",\"RR\",\"OW\",\"EM\",\"MT\",\"PL\",\"CC\",\"16\",\"24\",\"GP\",\n",
    "        \"BP\",\"DC\",\"CM\",\"CV\",\"ED\",\"NC\",\"WP\",\"SS\",\"SB\",\"SO\",\"MB\",\"WD\",\"OA\",\"WS\",\"AN\",\"PC\",\n",
    "        \"ML\",\"BE\"\n",
    "    ],\n",
    "    \"stop_name\": [\n",
    "        \"Richmond\",\"El Cerrito Del Norte\",\"El Cerrito Plaza\",\"North Berkeley\",\n",
    "        \"Downtown Berkeley\",\"Ashby\",\"MacArthur\",\"19th Street Oakland\",\n",
    "        \"12th Street / Oakland City Center\",\"Lake Merritt\",\"Fruitvale\",\"Coliseum - OAC\",\n",
    "        \"San Leandro\",\"Bay Fair\",\"Hayward\",\"South Hayward\",\"Union City\",\"Fremont\",\n",
    "        \"Concord\",\"Pleasant Hill / Contra Costa Centre\",\"Walnut Creek\",\"Lafayette\",\"Orinda\",\"Rockridge\",\n",
    "        \"West Oakland\",\"Embarcadero\",\"Montgomery Street\",\"Powell Street\",\n",
    "        \"Civic Center / UN Plaza\",\"16th Street / Mission\",\"24th Street / Mission\",\"Glen Park\",\n",
    "        \"Balboa Park\",\"Daly City\",\"Colma\",\"Castro Valley\",\"Dublin / Pleasanton\",\n",
    "        \"North Concord / Martinez\",\"Pittsburg / Bay Point\",\"South San Francisco\",\"San Bruno\",\n",
    "        \"San Francisco International Airport\",\"Millbrae (Caltrain Transfer Platform)\",\"West Dublin / Pleasanton\",\n",
    "        \"Oakland International Airport Station\",\"Warm Springs / South Fremont\",\"Antioch\",\"Pittsburg Center\",\n",
    "        \"Milpitas\",\"Berryessa / North San Jose\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "f645f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "GTFS_URL = \"https://www.bart.gov/dev/schedules/google_transit.zip\"\n",
    "\n",
    "response = requests.get(GTFS_URL)\n",
    "z = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "# Load GTFS components into DataFrames\n",
    "routes = pd.read_csv(z.open(\"routes.txt\"))\n",
    "stops = pd.read_csv(z.open(\"stops.txt\"))\n",
    "trips = pd.read_csv(z.open(\"trips.txt\"), dtype={\"route_id\": str})\n",
    "stop_times = pd.read_csv(z.open(\"stop_times.txt\"))\n",
    "calendar = pd.read_csv(z.open(\"calendar.txt\"))\n",
    "\n",
    "# Join trips with routes\n",
    "trip_routes = trips.merge(routes, on=\"route_id\", how=\"left\")\n",
    "\n",
    "# Join stop_times with stops\n",
    "times_with_stops = stop_times.merge(stops, on=\"stop_id\", how=\"left\")\n",
    "\n",
    "# Final joined table\n",
    "full_schedule = (\n",
    "    trip_routes\n",
    "    .merge(times_with_stops, on=\"trip_id\", how=\"left\")\n",
    "    .sort_values([\"route_id\", \"trip_id\", \"stop_sequence\"])\n",
    ")\n",
    "\n",
    "full_schedule['stop_name'] = full_schedule['stop_name'].str.replace(\"\", \"\", regex=False)\n",
    "\n",
    "mapped_schedule = full_schedule.merge(station_map_df, left_on=\"stop_name\", right_on=\"stop_name\", how=\"left\")\n",
    "\n",
    "# mapped_schedule.to_excel(\"C:/Users/chhri/Downloads/bart_full_schedule.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "92409b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_stop</th>\n",
       "      <th>to_stop</th>\n",
       "      <th>avg_ridership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>AN</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  from_stop to_stop  avg_ridership\n",
       "0        12      12             37\n",
       "1        12      16            182\n",
       "2        12      19             23\n",
       "3        12      24            144\n",
       "4        12      AN             91"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ridership_df.rename(columns={'Exit Station Two-Letter Code': 'from_stop'})\n",
    "\n",
    "# 2. Melt all OD columns into long form\n",
    "df_long = df.melt(\n",
    "    id_vars=['date', 'from_stop'],     # keep these as identifiers\n",
    "    var_name='to_stop',                # new column representing destination\n",
    "    value_name='ridership'             # ridership value\n",
    ")\n",
    "\n",
    "# 3. Drop rows where to_stop is NaN (your last row has a NaN column)\n",
    "df_long = df_long.dropna(subset=['to_stop'])\n",
    "\n",
    "# Optional: sort nicely\n",
    "df_long = df_long.sort_values(['date', 'from_stop', 'to_stop']).reset_index(drop=True)\n",
    "\n",
    "df_avg = (\n",
    "    df_long\n",
    "    .groupby(['from_stop', 'to_stop'], as_index=False)['ridership']\n",
    "    .mean()\n",
    "    .rename(columns={'ridership': 'avg_ridership'})\n",
    ")\n",
    "\n",
    "# Round up avg ridership to nearest integer and handle missing values\n",
    "df_avg['avg_ridership'] = df_avg['avg_ridership'].apply(lambda x: int(math.ceil(x)) if pd.notna(x) else 0)\n",
    "\n",
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "fe227e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_df = mapped_schedule.copy()\n",
    "\n",
    "def parse_gtfs_time(t):\n",
    "    \"\"\"\n",
    "    Parse time strings like '06:11:00' or '24:05:00' into minutes since midnight.\n",
    "    GTFS allows hours >= 24, meaning times past midnight but same service day.\n",
    "    \"\"\"\n",
    "    if pd.isna(t):\n",
    "        return np.nan\n",
    "    hh, mm, ss = map(int, str(t).split(\":\"))\n",
    "    return hh * 60 + mm + ss / 60.0   # minutes since midnight (possibly > 24*60)\n",
    "\n",
    "def compute_travel_times(stops_df):\n",
    "    df = stops_df.copy()\n",
    "\n",
    "    # parse times into numeric minutes\n",
    "    df[\"arr_min\"] = df[\"arrival_time\"].apply(parse_gtfs_time)\n",
    "    df[\"dep_min\"] = df[\"departure_time\"].apply(parse_gtfs_time)\n",
    "\n",
    "    # sort properly\n",
    "    df = df.sort_values([\"route_id\", \"trip_id\", \"stop_sequence\"])\n",
    "\n",
    "    arc_rows = []\n",
    "\n",
    "    for (route_id, trip_id), group in df.groupby([\"route_id\", \"trip_id\"]):\n",
    "        group = group.sort_values(\"stop_sequence\")\n",
    "\n",
    "        dep_times = group[\"dep_min\"].values\n",
    "        arr_times = group[\"arr_min\"].values\n",
    "        seq      = group[\"stop_sequence\"].values\n",
    "        codes    = group[\"code\"].values\n",
    "        dep_str  = group[\"departure_time\"].values\n",
    "        arr_str  = group[\"arrival_time\"].values\n",
    "\n",
    "        for i in range(len(group) - 1):\n",
    "            travel = arr_times[i+1] - dep_times[i]   # minutes\n",
    "            travel_min = int(round(travel))\n",
    "\n",
    "            arc_rows.append({\n",
    "                \"route_id\": route_id,\n",
    "                \"trip_id\": trip_id,\n",
    "                \"from_stop\": codes[i],\n",
    "                \"to_stop\": codes[i+1],\n",
    "                \"from_seq\": seq[i],\n",
    "                \"to_seq\": seq[i+1],\n",
    "                \"dep_time_str\": dep_str[i],\n",
    "                \"arr_time_str\": arr_str[i+1],\n",
    "                \"travel_time_min\": travel_min,\n",
    "                \"arr_time\": arr_times[i+1],\n",
    "                \"dep_time\": dep_times[i]\n",
    "            })\n",
    "    df = pd.DataFrame(arc_rows)\n",
    "\n",
    "    arc_rows = df.merge(df_avg, how='left', on=['from_stop','to_stop'])\n",
    "\n",
    "    return pd.DataFrame(arc_rows)\n",
    "\n",
    "arc_df = compute_travel_times(stops_df)\n",
    "arc_df['from_stop_to_stop'] = arc_df['from_stop'] + \"_\" + arc_df['to_stop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = arc_df['from_stop'] + \"_\" + arc_df['dep_time'] + \"_\" + arc_df['to_stop'] + \"_\" + arc_df['arr_time']\n",
    "\n",
    "# --- Clean arc list ---\n",
    "A = [a for a in arc_df['from_stop_to_stop'].unique() if isinstance(a, str)]\n",
    "\n",
    "# --- Build station set ---\n",
    "V = sorted(set(s for a in A for s in a.split(\"__\")))\n",
    "\n",
    "# --- Stage arcs (seq+1 arcs) ---\n",
    "A_stage = [\n",
    "    row['from_stop_to_stop']\n",
    "    for _, row in arc_df.iterrows()\n",
    "    if isinstance(row['from_stop_to_stop'], str)\n",
    "       and row['to_seq'] == row['from_seq'] + 1\n",
    "]\n",
    "A_stage = sorted(set(A_stage))\n",
    "\n",
    "# --- Overnight arcs (arrival next day) ---\n",
    "A_ov = [\n",
    "    row['from_stop_to_stop']\n",
    "    for _, row in arc_df.iterrows()\n",
    "    if isinstance(row['from_stop_to_stop'], str)\n",
    "       and row['arr_time'] < row['dep_time']\n",
    "]\n",
    "A_ov = sorted(set(A_ov))\n",
    "\n",
    "# --- Demand dictionary: d[a] = avg_ridership ---\n",
    "d = {\n",
    "    row['from_stop_to_stop']: row['avg_ridership']\n",
    "    for _, row in arc_df.iterrows()\n",
    "    if isinstance(row['from_stop_to_stop'], str)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "aaaac775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: 13th Gen Intel(R) Core(TM) i7-13700K, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 24 logical processors, using up to 24 threads\n",
      "\n",
      "Optimize a model with 290 rows, 98 columns and 410 nonzeros\n",
      "Model fingerprint: 0x2bd96400\n",
      "Variable types: 0 continuous, 98 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+00]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e-01, 2e+01]\n",
      "Presolve removed 2 rows and 0 columns\n",
      "Presolve time: 0.00s\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 24 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Model is infeasible\n",
      "Best objective -, best bound -, gap -\n"
     ]
    }
   ],
   "source": [
    "def build_train_fleet_model(V, A, A_stage, A_ov, d, m, units_per_train):\n",
    "    \"\"\"\n",
    "    Generic implementation of the model described in the screenshot.\n",
    "\n",
    "    Inputs:\n",
    "        V  : set of station-time nodes (list or iterable)\n",
    "        A  : set of all arcs (list of arc IDs)\n",
    "        A_stage : subset of A representing train stage arcs\n",
    "        A_ov    : subset of A representing overnight arcs\n",
    "        d  : dict mapping stage arc a -> required number of seats d[a]\n",
    "        m  : max seats per train (capacity constraint)\n",
    "        units_per_train : n in screenshot (seats per unit)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create model\n",
    "    model = Model(\"Train_Fleet_Optimization\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Decision Variables\n",
    "    # -----------------------------\n",
    "    # t[a] = number of train units assigned to arc a\n",
    "    t = model.addVars(A, vtype=GRB.INTEGER, lb=0, name=\"t\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Objective\n",
    "    # -----------------------------\n",
    "    # Minimize total units assigned on overnight arcs\n",
    "    model.setObjective(quicksum(t[a] for a in A_ov), GRB.MINIMIZE)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Constraints\n",
    "    # -----------------------------\n",
    "    # (1) Flow Conservation\n",
    "    # For each station-time node v:\n",
    "    #   sum outgoing = sum incoming\n",
    "    for v in V:\n",
    "        outgoing = [a for a in A if a.startswith(f\"{v.split('_')[0]}_\")]\n",
    "        incoming = [a for a in A if a.endswith(f\"_{v.split('_')[1]}\")]\n",
    "        model.addConstr(quicksum(t[a] for a in outgoing) ==\n",
    "                        quicksum(t[a] for a in incoming),\n",
    "                        name=f\"flow_{v}\")\n",
    "\n",
    "    # (2) Capacity Constraint\n",
    "    # t[a] ≤ m for each stage arc a ∈ A_stage\n",
    "    for a in A_stage:\n",
    "        model.addConstr(t[a] <= m, name=f\"capacity_{a}\")\n",
    "\n",
    "    # (3) Demand Constraint\n",
    "    # n * t[a] ≥ d[a]\n",
    "    for a in A_stage:\n",
    "        model.addConstr(m * t[a] >= d[a]/54, name=f\"demand_{a}\")\n",
    "\n",
    "    # (4) Integrality is already handled by variable type\n",
    "\n",
    "    return model.optimize()\n",
    "\n",
    "build_train_fleet_model(\n",
    "    V,\n",
    "    A,\n",
    "    A_stage,\n",
    "    A_ov,\n",
    "    d,\n",
    "    6,\n",
    "    54\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "2d8baeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: 13th Gen Intel(R) Core(TM) i7-13700K, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 16 physical cores, 24 logical processors, using up to 24 threads\n",
      "\n",
      "Optimize a model with 290 rows, 98 columns and 410 nonzeros\n",
      "Model fingerprint: 0x2bd96400\n",
      "Variable types: 0 continuous, 98 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+00]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e-01, 2e+01]\n",
      "Presolve removed 2 rows and 0 columns\n",
      "Presolve time: 0.00s\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 24 available processors)\n",
      "\n",
      "Solution count 0\n",
      "\n",
      "Model is infeasible\n",
      "Best objective -, best bound -, gap -\n"
     ]
    }
   ],
   "source": [
    "def build_train_fleet_model(V, A, A_stage, A_ov, d, m, units_per_train):\n",
    "    \"\"\"\n",
    "    Generic implementation of the model described in the screenshot.\n",
    "\n",
    "    Inputs:\n",
    "        V  : set of station-time nodes (list or iterable)\n",
    "        A  : set of all arcs (list of arc IDs)\n",
    "        A_stage : subset of A representing train stage arcs\n",
    "        A_ov    : subset of A representing overnight arcs\n",
    "        d  : dict mapping stage arc a -> required number of seats d[a]\n",
    "        m  : max seats per train (capacity constraint)\n",
    "        units_per_train : n in screenshot (seats per unit)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create model\n",
    "    model = Model(\"Train_Fleet_Optimization\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Decision Variables\n",
    "    # -----------------------------\n",
    "    # t[a] = number of train units assigned to arc a\n",
    "    t = model.addVars(A, vtype=GRB.INTEGER, lb=0, name=\"t\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Objective\n",
    "    # -----------------------------\n",
    "    # Minimize total units assigned on overnight arcs\n",
    "    model.setObjective(quicksum(t[a] for a in A_ov), GRB.MINIMIZE)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Constraints\n",
    "    # -----------------------------\n",
    "    # (1) Flow Conservation\n",
    "    # For each station-time node v:\n",
    "    #   sum outgoing = sum incoming\n",
    "    for v in V:\n",
    "        outgoing = [a for a in A if a.startswith(f\"{v.split('_')[0]}_\")]\n",
    "        incoming = [a for a in A if a.endswith(f\"_{v.split('_')[1]}\")]\n",
    "        model.addConstr(quicksum(t[a] for a in outgoing) ==\n",
    "                        quicksum(t[a] for a in incoming),\n",
    "                        name=f\"flow_{v}\")\n",
    "\n",
    "    # (2) Capacity Constraint\n",
    "    # t[a] ≤ m for each stage arc a ∈ A_stage\n",
    "    for a in A_stage:\n",
    "        model.addConstr(t[a] <= m, name=f\"capacity_{a}\")\n",
    "\n",
    "    # (3) Demand Constraint\n",
    "    # n * t[a] ≥ d[a]\n",
    "    for a in A_stage:\n",
    "        model.addConstr(m * t[a] >= d[a]/54, name=f\"demand_{a}\")\n",
    "\n",
    "    # (4) Integrality is already handled by variable type\n",
    "\n",
    "    return model.optimize()\n",
    "\n",
    "build_train_fleet_model(\n",
    "    V,\n",
    "    A,\n",
    "    A_stage,\n",
    "    A_ov,\n",
    "    d,\n",
    "    6,\n",
    "    54\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "1cc9eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AN_PC',\n",
       " 'PC_WP',\n",
       " 'WP_NC',\n",
       " 'NC_CN',\n",
       " 'CN_PH',\n",
       " 'PH_WC',\n",
       " 'WC_LF',\n",
       " 'LF_OR',\n",
       " 'OR_RR',\n",
       " 'RR_MA',\n",
       " 'MA_19',\n",
       " '19_12',\n",
       " '12_OW',\n",
       " 'OW_EM',\n",
       " 'EM_MT',\n",
       " 'MT_PL',\n",
       " 'PL_CC',\n",
       " 'CC_16',\n",
       " '16_24',\n",
       " '24_GP',\n",
       " 'GP_BP',\n",
       " 'BP_DC',\n",
       " 'DC_CM',\n",
       " 'CM_SS',\n",
       " 'SS_SB',\n",
       " 'SB_SO',\n",
       " 'SO_SO',\n",
       " 'SO_MB',\n",
       " 'SB_MB',\n",
       " 'ED_WD',\n",
       " 'WD_CV',\n",
       " 'CV_BF',\n",
       " 'BF_SL',\n",
       " 'FV_LM',\n",
       " 'LM_OW',\n",
       " 'DC_BP',\n",
       " 'BP_GP',\n",
       " 'GP_24',\n",
       " '24_16',\n",
       " '16_CC',\n",
       " 'CC_PL',\n",
       " 'PL_MT',\n",
       " 'MT_EM',\n",
       " 'EM_OW',\n",
       " 'OW_LM',\n",
       " 'LM_FV',\n",
       " 'SL_BF',\n",
       " 'BF_CV',\n",
       " 'CV_WD',\n",
       " 'WD_ED',\n",
       " 'OA_CL',\n",
       " 'MB_SO',\n",
       " 'SO_SB',\n",
       " 'SB_SS',\n",
       " 'SS_CM',\n",
       " 'CM_DC',\n",
       " 'OW_12',\n",
       " '12_19',\n",
       " '19_MA',\n",
       " 'MA_RR',\n",
       " 'RR_OR',\n",
       " 'OR_LF',\n",
       " 'LF_WC',\n",
       " 'WC_PH',\n",
       " 'PH_CN',\n",
       " 'CN_NC',\n",
       " 'NC_WP',\n",
       " 'WP_PC',\n",
       " 'PC_AN',\n",
       " 'CL_OA',\n",
       " 'SH_HY',\n",
       " 'HY_BF',\n",
       " 'LM_12',\n",
       " 'MA_AS',\n",
       " 'AS_BK',\n",
       " 'BK_NB',\n",
       " 'NB_EP',\n",
       " 'EP_EN',\n",
       " 'EN_RM',\n",
       " 'FM_UC',\n",
       " 'UC_SH',\n",
       " 'BE_ML',\n",
       " 'ML_WS',\n",
       " 'WS_FM',\n",
       " 'RM_EN',\n",
       " 'EN_EP',\n",
       " 'EP_NB',\n",
       " 'NB_BK',\n",
       " 'BK_AS',\n",
       " 'AS_MA',\n",
       " '12_LM',\n",
       " 'BF_HY',\n",
       " 'HY_SH',\n",
       " 'SH_UC',\n",
       " 'UC_FM',\n",
       " 'FM_WS',\n",
       " 'WS_ML',\n",
       " 'ML_BE']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
